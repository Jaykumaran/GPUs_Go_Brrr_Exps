{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[],"dockerImageVersionId":30919,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nfrom torchvision.transforms import transforms\nimport torch.optim as optim\nfrom torchinfo import summary\nimport torchvision\n\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available  else \"cpu\")\nprint(\"Using device: \", device)\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = torchvision.models.resnet18(weights = 'DEFAULT')\nmodel.fc = nn.Linear(model.fc.in_features, 10)\n\n# summary(model, (1, 3, 224, 224), device = \"cpu\")\nmodel.to(device) # move to gpu\nprint(\"--- Model Loaded --- \")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Simple DataParallel to use Kaggle T4 2 GPus","metadata":{}},{"cell_type":"code","source":"if torch.cuda.device_count() > 1:\n    print(f\"Using {torch.cuda.device_count()} GPUs\")\n    model = nn.DataParallel(model)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\ntrain_set = torchvision.datasets.CIFAR10(root = \"./data\", download = True, train = True, transform = transform)\n\ntrain_loader = DataLoader(train_set, batch_size = 32, shuffle = True, num_workers = 2)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"num_epochs = 5\n\n\nfor i, (images, labels) in enumerate(trainloader, start = 0):\n    running_loss = 0.0\n    images, labels = images.to(device), labels.to(device)\n\n    optimizer.zero_grad(set_to_none = True)\n    prediction = model(images)\n    loss = criterion(prediction, labels)\n\n    pred_idx = prediction.argmax(dim = 1)\n    loss.backward()\n    optimizer.step()\n\n    running_loss = loss.item() \n\n\n    if i % 100 == 99: # print every 100 mini-batches\n       print(f\"Epoch : {i + 1} ; Loss : {running_loss  / 100:.3f}\")\n       running_loss = 0.0\n\nprint(\"Finished Training\")\n\n\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### Distributed DataParallelism - (need fix)","metadata":{}},{"cell_type":"code","source":"%%writefile train.py\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import DataLoader\nimport torch.distributed as dist\nfrom torch.nn.parallel import DistributedDataParallel as DDP\nimport os\nfrom tqdm import tqdm  # Import tqdm\n\n# Initialize the process group for DDP (for multi-GPU training)\ndef init_process_group(rank, world_size):\n    os.environ['RANK'] = str(rank)\n    os.environ['WORLD_SIZE'] = str(world_size)\n    os.environ['MASTER_ADDR'] = 'localhost'  # Set master address\n    os.environ['MASTER_PORT'] = '12355'  # Set master port (use an unused port)\n    \n    dist.init_process_group(backend='nccl', init_method='env://', rank=rank, world_size=world_size)\n\n# Set device to CUDA if available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nprint(f\"Using device: {device}\")\n\n# Model definition (ResNet18 example)\nmodel = torchvision.models.resnet18(pretrained=True)\nmodel.fc = nn.Linear(model.fc.in_features, 10)  # Modify for 10 output classes (CIFAR10)\nmodel = model.to(device)\n\n# Manually set rank (0 for first GPU, 1 for second GPU)\nrank = torch.cuda.current_device()  # This sets the rank based on the current device\nworld_size = torch.cuda.device_count()  # Number of GPUs available (2 in Kaggle)\n\n# Initialize the process group and wrap the model with DDP\ninit_process_group(rank, world_size)\n\n# DDP requires wrapping the model after initializing the process group\nmodel = DDP(model, device_ids=[rank])\n\n# Dataset and DataLoader\ntransform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])\n\ntrainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\ntrainloader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=2)\n\n# Loss function and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n\n# Training loop\nnum_epochs = 5\nfor epoch in range(num_epochs):\n    running_loss = 0.0\n    \n    # Use tqdm for a progress bar in the loop\n    loop = tqdm(enumerate(trainloader, 0), total=len(trainloader), desc=f\"Epoch {epoch+1}/{num_epochs}\", dynamic_ncols=True)\n\n    for i, data in loop:\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        # Zero the parameter gradients\n        optimizer.zero_grad()\n\n        # Forward pass\n        outputs = model(inputs)\n\n        # Compute loss\n        loss = criterion(outputs, labels)\n\n        # Backward pass\n        loss.backward()\n\n        # Optimize the model\n        optimizer.step()\n\n        # Update the progress bar with the loss\n        running_loss += loss.item()\n        if i % 100 == 99:  # Print every 100 mini-batches\n            loop.set_postfix(loss=running_loss / 100)\n            running_loss = 0.0  # Reset running loss after logging\n\nprint(\"Finished Training\")\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"!python train.py","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# Reference: https://github.com/dnddnjs/pytorch-multigpu/blob/master/dist_parallel/train.py","metadata":{}},{"cell_type":"code","source":"!pip install tensorboardX -q","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"%%writefile train.py\n\nimport os\nimport time\nimport datetime\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torch.backends.cudnn as cudnn\n\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import CIFAR10\nfrom torch.utils.data import DataLoader\n\nimport torch.distributed as dist\nimport torch.multiprocessing as mp\nimport torch.utils.data.distributed\n\n# from model import pyramidnet\nimport argparse\nfrom tensorboardX import SummaryWriter\n\n\nparser = argparse.ArgumentParser(description='cifar10 classification models')\nparser.add_argument('--lr', default=0.1, help='')\nparser.add_argument('--resume', default=None, help='')\nparser.add_argument('--batch_size', type=int, default=768, help='')\nparser.add_argument('--num_workers', type=int, default=4, help='')\nparser.add_argument(\"--gpu_devices\", type=int, nargs='+', default=None, help=\"\") \n# nargs can take more than value, as a list  --> if only one value is passed it is treated as non-iter then it may throw error TypeError: 'list' object cannot be interpreted as an integer\n\nparser.add_argument(\"--epochs\", type=int, default=None, help=\"\")\n\nparser.add_argument('--gpu', default=None, type=int, help='GPU id to use.')\nparser.add_argument('--dist-url', default='tcp://127.0.0.1:3456', type=str, help='')\nparser.add_argument('--dist-backend', default='nccl', type=str, help='')\nparser.add_argument('--rank', default=0, type=int, help='')\nparser.add_argument('--world_size', default=1, type=int, help='')\nparser.add_argument('--distributed', action='store_true', help='')\nargs = parser.parse_args()\n\ngpu_devices = ','.join([str(id) for id in args.gpu_devices])\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = gpu_devices\n\n\nmodel = torchvision.models.resnet18(weights = 'DEFAULT')\nmodel.fc = nn.Linear(model.fc.in_features, 10)\n\n# summary(model, (1, 3, 224, 224), device = \"cpu\")\n# model.to(device) # move to gpu\nprint(\"--- Model Loaded --- \")\n\n\ndef main():\n    args = parser.parse_args()\n\n    ngpus_per_node = torch.cuda.device_count()\n\n    args.world_size = ngpus_per_node * args.world_size\n    mp.spawn(main_worker, nprocs=ngpus_per_node, args=(ngpus_per_node, args))\n        \n        \ndef main_worker(gpu, ngpus_per_node, args):\n    args.gpu = gpu\n    ngpus_per_node = torch.cuda.device_count()    \n    print(\"Use GPU: {} for training\".format(args.gpu))\n        \n    args.rank = args.rank * ngpus_per_node + gpu    \n    dist.init_process_group(backend=args.dist_backend, init_method=args.dist_url,\n                            world_size=args.world_size, rank=args.rank)\n\n    print('==> Making model..')\n    net = model\n    torch.cuda.set_device(args.gpu)\n    net.cuda(args.gpu)\n    args.batch_size = int(args.batch_size / ngpus_per_node)\n    args.num_workers = int(args.num_workers / ngpus_per_node)\n    net = torch.nn.parallel.DistributedDataParallel(net, device_ids=[args.gpu])\n    num_params = sum(p.numel() for p in net.parameters() if p.requires_grad)\n    print('The number of parameters of model is', num_params)\n\n    print('==> Preparing data..')\n    transforms_train = transforms.Compose([\n        transforms.RandomCrop(32, padding=4),\n        transforms.RandomHorizontalFlip(),\n        transforms.ToTensor(),\n        transforms.Normalize((0.4914, 0.4822, 0.4465), (0.2023, 0.1994, 0.2010))])\n\n    dataset_train = CIFAR10(root='./data', train=True, download=True, \n                            transform=transforms_train)\n    train_sampler = torch.utils.data.distributed.DistributedSampler(dataset_train)\n    train_loader = DataLoader(dataset_train, batch_size=args.batch_size, \n                              shuffle=(train_sampler is None), num_workers=args.num_workers, \n                              sampler=train_sampler)\n\n    # there are 10 classes so the dataset name is cifar-10\n    classes = ('plane', 'car', 'bird', 'cat', 'deer', \n               'dog', 'frog', 'horse', 'ship', 'truck')\n    \n    criterion = nn.CrossEntropyLoss()\n    optimizer = optim.SGD(net.parameters(), lr=args.lr, \n                          momentum=0.9, weight_decay=1e-4)\n    num_epochs = args.epochs\n    for epoch in range(num_epochs):\n        train(net, criterion, optimizer, train_loader, args.gpu)\n            \n\ndef train(net, criterion, optimizer, train_loader, device):\n    net.train()\n\n    train_loss = 0\n    correct = 0\n    total = 0\n    \n    epoch_start = time.time()\n    for batch_idx, (inputs, targets) in enumerate(train_loader):\n        start = time.time()\n        \n        inputs = inputs.cuda(device)\n        targets = targets.cuda(device)\n        outputs = net(inputs)\n        loss = criterion(outputs, targets)\n\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()\n        _, predicted = outputs.max(1)\n        total += targets.size(0)\n        correct += predicted.eq(targets).sum().item()\n\n        acc = 100 * correct / total\n        \n        batch_time = time.time() - start\n        \n        if batch_idx % 20 == 0:\n            print('Epoch: [{}/{}]| loss: {:.3f} | acc: {:.3f} | batch time: {:.3f}s '.format(\n                batch_idx, len(train_loader), train_loss/(batch_idx+1), acc, batch_time))\n    \n    elapse_time = time.time() - epoch_start\n    elapse_time = datetime.timedelta(seconds=elapse_time)\n    print(\"Training time per epoch {}\".format(elapse_time))\n    \n\nif __name__=='__main__':\n    main()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T18:56:48.394850Z","iopub.execute_input":"2025-03-08T18:56:48.395166Z","iopub.status.idle":"2025-03-08T18:56:48.401773Z","shell.execute_reply.started":"2025-03-08T18:56:48.395136Z","shell.execute_reply":"2025-03-08T18:56:48.400943Z"}},"outputs":[{"name":"stdout","text":"Overwriting train.py\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# cd dist_parallel\n# For Kaggle T4x2 So we pass two ids\n!python train.py --gpu_device 0 1  --batch_size 768 --epochs 5","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-03-08T18:56:48.504441Z","iopub.execute_input":"2025-03-08T18:56:48.504671Z","iopub.status.idle":"2025-03-08T18:59:52.962173Z","shell.execute_reply.started":"2025-03-08T18:56:48.504652Z","shell.execute_reply":"2025-03-08T18:59:52.961362Z"}},"outputs":[{"name":"stdout","text":"--- Model Loaded --- \n--- Model Loaded --- \nUse GPU: 1 for training\n--- Model Loaded --- \nUse GPU: 0 for training\n==> Making model..\n==> Making model..\nThe number of parameters of model is The number of parameters of model is11181642 \n11181642==> Preparing data..\n\n==> Preparing data..\nFiles already downloaded and verifiedFiles already downloaded and verified\n\n--- Model Loaded --- \n--- Model Loaded --- \n--- Model Loaded --- \n--- Model Loaded --- \nEpoch: [0/66]| loss: 2.560 | acc: 11.458 | batch time: 0.807s \nEpoch: [0/66]| loss: 2.609 | acc: 13.802 | batch time: 0.931s \nEpoch: [20/66]| loss: 2.093 | acc: 34.772 | batch time: 0.095s \nEpoch: [20/66]| loss: 2.130 | acc: 34.338 | batch time: 0.092s \nEpoch: [40/66]| loss: 1.876 | acc: 42.124 | batch time: 0.096s Epoch: [40/66]| loss: 1.819 | acc: 42.537 | batch time: 0.093s \n\nEpoch: [60/66]| loss: 1.857 | acc: 43.327 | batch time: 0.097s \nEpoch: [60/66]| loss: 1.814 | acc: 43.716 | batch time: 0.096s \nTraining time per epoch 0:00:32.633945\nTraining time per epoch 0:00:32.641387\n--- Model Loaded --- \n--- Model Loaded --- \n--- Model Loaded --- \n--- Model Loaded --- \nEpoch: [0/66]| loss: 2.301 | acc: 20.573 | batch time: 0.209s \nEpoch: [0/66]| loss: 2.623 | acc: 16.667 | batch time: 0.163s \nEpoch: [20/66]| loss: 2.263 | acc: 18.242 | batch time: 0.214s \nEpoch: [20/66]| loss: 2.346 | acc: 18.973 | batch time: 0.091s \nEpoch: [40/66]| loss: 2.221 | acc: 21.316 | batch time: 0.091s Epoch: [40/66]| loss: 2.255 | acc: 20.389 | batch time: 0.189s \n\nEpoch: [60/66]| loss: 2.176 | acc: 22.878 | batch time: 0.165s \nEpoch: [60/66]| loss: 2.192 | acc: 23.045 | batch time: 0.095s \nTraining time per epoch 0:00:31.929263\nTraining time per epoch 0:00:31.980167\n--- Model Loaded --- \n--- Model Loaded --- \n--- Model Loaded --- \n--- Model Loaded --- \nEpoch: [0/66]| loss: 2.585 | acc: 21.875 | batch time: 0.179s \nEpoch: [0/66]| loss: 2.154 | acc: 25.260 | batch time: 0.162s \nEpoch: [20/66]| loss: 2.332 | acc: 25.893 | batch time: 0.099s \nEpoch: [20/66]| loss: 2.220 | acc: 26.662 | batch time: 0.158s \nEpoch: [40/66]| loss: 2.144 | acc: 28.411 | batch time: 0.140s \nEpoch: [40/66]| loss: 2.074 | acc: 28.792 | batch time: 0.090s \nEpoch: [60/66]| loss: 2.003 | acc: 29.982 | batch time: 0.100s Epoch: [60/66]| loss: 2.043 | acc: 29.884 | batch time: 0.151s \n\nTraining time per epoch 0:00:31.931349\nTraining time per epoch 0:00:31.986527\n--- Model Loaded --- \n--- Model Loaded --- \n--- Model Loaded --- \n--- Model Loaded --- \nEpoch: [0/66]| loss: 1.842 | acc: 31.250 | batch time: 0.164s \nEpoch: [0/66]| loss: 1.904 | acc: 32.031 | batch time: 0.273s \nEpoch: [20/66]| loss: 1.819 | acc: 31.994 | batch time: 0.174s Epoch: [20/66]| loss: 1.850 | acc: 31.213 | batch time: 0.101s \n\nEpoch: [40/66]| loss: 1.788 | acc: 33.708 | batch time: 0.091s \nEpoch: [40/66]| loss: 1.767 | acc: 34.210 | batch time: 0.126s \nEpoch: [60/66]| loss: 1.739 | acc: 35.468 | batch time: 0.103s Epoch: [60/66]| loss: 1.742 | acc: 35.489 | batch time: 0.103s \n\nTraining time per epoch 0:00:32.106406\nTraining time per epoch 0:00:32.100638\n--- Model Loaded --- \n--- Model Loaded --- \n--- Model Loaded --- \n--- Model Loaded --- \nEpoch: [0/66]| loss: 1.692 | acc: 35.938 | batch time: 0.417s Epoch: [0/66]| loss: 1.672 | acc: 39.323 | batch time: 0.156s \n\nEpoch: [20/66]| loss: 1.708 | acc: 37.140 | batch time: 0.102s \nEpoch: [20/66]| loss: 1.675 | acc: 38.777 | batch time: 0.108s \nEpoch: [40/66]| loss: 1.636 | acc: 39.685 | batch time: 0.104s \nEpoch: [40/66]| loss: 1.665 | acc: 38.523 | batch time: 0.102s \nEpoch: [60/66]| loss: 1.611 | acc: 40.450 | batch time: 0.099s \nEpoch: [60/66]| loss: 1.625 | acc: 40.027 | batch time: 0.115s \nTraining time per epoch 0:00:32.473986\nTraining time per epoch 0:00:32.477097\n[rank0]:[W308 18:59:50.301727817 ProcessGroupNCCL.cpp:1250] Warning: WARNING: process group has NOT been destroyed before we destruct ProcessGroupNCCL. On normal program exit, the application should call destroy_process_group to ensure that any pending NCCL operations have finished in this process. In rare cases this process can exit before this point and block the progress of another member of the process group. This constraint has always been present,  but this warning has only been added since PyTorch 2.4 (function operator())\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}